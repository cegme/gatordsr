

\section{Implementation}
\label{section:implementation}

We extract aliases for entities from Wikipedia automatically both using API 
and using the actual page content, then apply pattern matching rules for slot 
value extraction. Our contribution is that we perform pattern matching that conforms to each slot 
value along with post-processings to eliminate noisy outputs. 

%\ceg{Instead of this paragraph we talk about what this %section will
%contain. We can discuss the input/output of the system %too.
%}

\subsection{Alias Generation}
\label{section:aliasgeneration}

We use Wikipedia API to get some aliases automatically. This is done by 
retrieving backlink references (redirects of a wiki entity). Unfortunately 
this is not good enough and to enhance recall we need more aliases. To have 
better use of a wiki page we parse HTML DOM of the page, then use regular 
expressions to extract the bold phrases of the first paragraph as alias of the 
actual entity. Based on our observation this is a very accurate heuristic and 
provides us with lots of famous aliases of the entities. To consider other 
typical cases we consider some generic first name last name order swapping 
conventions such as Bill Gates $\rightarrow$ Gates, Bill.  Meanwhile, William Henry Gates is an alias for Bill Gates in WP as a backlink reference. These kinds of aliases are also included in matching entities. 

\subsection{Streaming Slot Value Extraction}

\begin{figure}
\centering
%\includegraphics[width=4.5in]{./images/system.eps}
\includegraphics[width=6in]{./images/Pattern.eps}
\vspace*{-.1in} \caption{Pattern Matching with Slot Value on the Right Side of Entity. }\label{fig:pattern}
\vspace*{-.2in}
\end{figure}

In this system, we use pattern matching methods to find corresponding slot 
values for entities. This is done by observing the training data which is the first four months of the corpus (October 2011 - February 2012). The procedure is: First Find stream items that contain the 
entities by using alias names of the entities. Then Inside these stream items, 
fetch the sentences which contain entities by using alias names and the 
coreference information provided by Lingpipe tags. Use these sentences to 
match existing patterns, and when patterns matched, generate SSF results.

Each pattern consists of five fields:

\begin{itemize}
\item Type of the entity
\item Slot name
\item Pattern content
\item Direction of the slot value to the entity
\item Type of the slot values
\end{itemize}

 When we match one pattern, we match all the 
fields except the third field, which is extracted as the final result.

 The type of slot values could be the entity 
type tagged by Lingpipe, noun phrase tagged by OpenNLP and the time phrases we 
hard-code. For these three kinds of patterns, we implement them in different 
ways accordingly. Next we will explain the patterns with more details, a brief example can be found in Figure \ref{fig:pattern}. 

\textbf{Slot value type, tagged by Lingpipe:} For slot FounderOf, we have this
pattern: \textless \texttt{PER, FounderOf, founder, right, ORG}\textgreater. PER means 
that the entity we are finding slot values for is a PER entity; FounderOf 
means this is a pattern for FounderOf slot. Founder is the anchor word we are 
trying to match in the sentence text; right means that we are going to the 
right part of the sentence to match the pattern and find the slot value; ORG 
means the slot value should be a ORG entity.

\textbf{Slot value tagged as noun phrase by OpenNLP:} \textless \texttt{PER, AwardsWon, awarded, 
right, NP}\textgreater, NP meaning noun phrase. This pattern can be interpreted 
as that we are looking for a noun phrase after the “awarded'' since that noun 
phrase could possibly represent an award. Since titles and awards are usually 
not the Lingpipe entities, we use the OpenNLP noun phrase chunker to fetch the 
noun phrases.

\textbf{Slot value of time phrases, hard coded:} \textless \texttt{PER, DateOfDeath, died, right, 
last night}\textgreater. In this pattern, “last night'' means we are looking for 
exactly the phrase ``last night'' to the right of ``died''. This pattern is 
inspired by the intuition that in news articles, people often mention that 
somebody died last night instead of mentioning the accurate date information 
and Lingpipe tends not to tag phrases like ``last night'' as a DATE entity. 

To improve recall, we introduce generic patterns that can generate many results.
But these patterns generate many errors, too. Thus there is a trade-off 
between the accuracy and recall. This is one drawback of using pattern 
matching method, meaning it is really hard to find good patterns with both 
high accuracy and recall. 

For accuracy, we have found that there are three major kinds of errors: First,  
wrong entities found; next, wrong tags by the Lingpipe; and finally wrong results matched 
by the patterns. We solve the first problem by using the Wikipedia or twitter 
information of the entities to get better alias names. And we use
post-processing to reduce the second and third types of errors (Section \ref{section:highAccuracyFilter}).

\subsection{High Accuracy Filter}
\label{section:highAccuracyFilter}

The SSF output of many extractions is noisy. The data contains duplicates and 
incorrect extractions. We can define rules to sanitize the output only using 
the information present in the SSF file. The file is processed in time order, 
in a tuple-at-a-time fashion to minimize the impact on accuracy. We define 
two classes of rules: deduplication rules and inference rules.

The output contains many duplicate entries. As we read the list of extracted 
slots we create rules to define ``duplicate''. Duplicates can be present in a 
window of rows; we use a window size of 2 meaning we only be adjacent rows. 
Two rows are duplicates if they have the same exact extraction, or if the 
rows have the same slot name and a similar slot value or if the extracted 
sentence for a particular slot types come from the same sentence.

 New slots can be deduced from existing slots by defining inference rules. 
 For example, two slots for the task are ``FounderOf'' and ``FoundedBy''. A safe 
 assumption is these slot names are biconditional logical connectives with the 
 entities and slot values. Therefore, we can express a rule ``X FounderOf Y'' 
 equals ``Y FoundedBy X'' where X and Y are single unique entities. Additionally,
 we found that the slot names ``Contact\_Meet\_PlaceTime'' could be inferred as
 ``Contact\_Meet\_Entity'' if the Entity was a FAC and the extracted sentence 
 contained an additional ORG/FAC tag.  
We also remove erronious slots that have extractions that are several pages in 
length or tool small. Errors of extracting long sentences can typically be 
attributed to poor sentence parsing of web documents. We have some valid
``small'' extractions. For example a comma may separate a name and a title
(e.g. ``John, Professor at MIT''). But such extraction rules can be particularly 
noisy, so we check to see if the extracted values have good entity values.


% Note: Talk about how each of the algorithms were created

% Note: Give enough information for our algorithms to be
% reimplemented and verified.

