

\section{Discussion \& Future Works}

In this section we address some of the challenges that we faced during the course of this project. We started 
off by trying to use the off-the-shelf tools for this task. Mainly we started 
by using Scala/Spark\cite{ferc11} to benefit from the parallelization 
performance there. Unfortunately Spark was not performant and the distributed reliability overhead 
was much more than tolerable. We moved on to use Scala parallelization  framework itself, and unfortunately it did not satisfy our needs as well; there was 
excessive memory overhead on map-reduce jobs. We migrated the core of the 
system to Java Parallelism APIs and that was not good enough either, we still demanded 
better. So we built our own parallel system which in actual performance had 
the least of overhead, the least memory consumption and the most robust memory 
model which avoided unpredictable CPU stalls on garbage collections in 
processing the corpus.

As mentioned before, when we evaluate the results of slot extraction, we find 
three kinds of problems for accuracy: 1) wrong entities found; 2) wrong tags 
by the Lingpipe; 3) wrong results matched by the patterns.  We also have 
recall problems: 1) not enough good alias names to find all the entities. 2) 
not enough and powerful patterns to capture all the slot values. 

We will use entity resolution methods and other advanced methods to improve 
the accuracy and recall of entity extraction part. 

For slot extraction, to improve the performance, we need: 1) Using multi-class classifiers instead of pattern matching method to 
extract slot values in order to increase both recall and accuracy for slots
``Affiliate'', ``AssociateOf'', ``FounderOf'', ``EmployeeOf'', ``FoundedBy'',
``TopMembers'', ``Contact\_Meet\_Entity'' and so on. 2) For special slots, 
like ``Titles'', ``DateOfDeath'', ``CauseOfDeath'', ``AwardsWon'', using different 
kind of advanced methods, e.g.\ classifiers, matching methods. 3) Using other 
NLP tools or using classifiers to overcome the drawbacks of the LingPipeâ€™s 
inaccurate tags. The first and second tasks are the most important tasks we 
need to do.

About 50\% of twitter entities are not found by the system. One reason could be 
that those entities are not very famous. For example Brenda Weiler google 
search result has 860,000 documents over the whole web. For our 
small portion of the web it might make sense. If you pay attention to the 
histogram of the entities found you'll note that more than half of the 
entities have appeared in less than 10 StreamItems. A good portion have 
appeared only once. Which the document does not necessarily have good 
information for us.

A theory is that we are falling behind because we are using the cleansed (from HTML tags)
version of the corpus. We believe there has been a reason that TREC has 
included the actual HTML document as well as the cleansed version. This 
definitely will convey some information to us. If it was as easy as reading 
some clean text they wouldn't bother including so much data for teams to be 
useless. So we guess is that we are missing some information from not using 
the actual document. And, we are looking for tokens with entity value set 
which will depend us dramatically on the accuracy of lingpipe, which is a fast 
algorithm but is not as good as other NLP tools can be e.g. Stanford NLP.

% Note: Here we discuss why the results are the way they are
% Give pros and cons, talk about how the implemented algorithms
% performed in the actual implementation.
% Answer the `why' question about all the trends in the results section.

