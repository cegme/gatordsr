
\section{Introduction}

One of the important challenges in maintaining the most popular free, web-based, collaborative, multilingual encyclopedia in the internet (Wikipedia) is to make sure its descriptions are upto date. It has been observed that there is a considerable time lag between the publication date of cited news articles and the date of an edit to Wikipedia (WP) creating the citation. In a case-study, the time lag for a sample of \~60,000 web pages cited by WP articles in the Living\_people category, The median time is over a year and the distribution has a long and heavy tail\cite{JFrank12}. It is also noted that the majority of wikipedia entities have updates on their WP article much less frequently than their mention frequency.

Such stale entries are the norm in any large knowledge base (KB), because the number of humans maintaining the knowledge base is far fewer than the number of entities in the KB. Further, the number of mentions is much larger than the number of entities. This mismatch between human maintainers and the large stream of mentions to entities of interest is effectively a definition of a ``large'' KB \cite{JFrank12}. So, knowledge-bases are important and we are working on accelerating populating them.

In this article we will describe the approach the GatorDSR team from the 
University of Florida in addressing the challenge at NIST’s Text 
REtrieval Conference (TREC) --- Knowledge Base Acceleration track 2013 
In the first section we describe 
the system design and articulate its evolution during the whole process, 
challenges and needs that we have overcome. In the second section we will go 
through the details of the NLP techniques we took at streaming slot filling
(SSF): given a slot name (entity + relation type) we fill in the slot value
(relation value) on structured text documents. For similar approaches regarding last year's track you can refer to \cite{ji2011knowledge}.

%\ceg{Add a discussion of why machine driven kb population is important.}
The task is that given certain Wikipedia or Twitter entities 
(wiki/twitter URLs) and certain relations of interest given in Table  \ref{table:slotNameOntology}, extract as many triple relations as possible (hence, slot filling). This can be used to automatically populate knowledgebases such as free-base or DBPedia 
or even filling in the information boxes at Wikipedia. The corpus is in 
English and is a snapshot of part of the web containing document types described in Table \ref{table:documentsDist}. Each document is annotated using lingpipe and is called StreamItem, a bundle of 
StreamItems are put together and serialized as Apache Thrift objects, then 
compressed using xz compression with Lempel–Ziv–Markov chain algorithm (LZMA2) 
and finally encrypted using GNU Privacy Guard (GPG) with RSA asymmetric keys.
To have a sense of the scale of objects and compression as an example a 6mb
gpg.xz files would become 45 mb thrift objects which can contain a couple of 
thousand StreamItems depending on their size. Some of the documents have null 
values for their annotation fields.

Since this is \textit{streaming} slot filling, we are only interested in new 
slot values that were not substantiated earlier in the stream corpus, which 
ranges from October 2011 to February 2013. Below you can view some slot values 
and their types, the comprehensive description of which can be found at
\cite{tackbp} and \cite{aec}. These examples demonstrate that out of an ordinary sentence in the general web, which parts are of interest for us and which should be avoided to be returned as slot values of a given entity. You can view that sometimes it can get fairly complex, so a good extraction scheme is essential. The evaluation metric is that the extractions will be submitted to KBA assessors and they will determine the overall performance for comparison.

Assessors were instructed to ``use the wikipedia article to identify (disambiguate) the entity, and then imagine forgetting all info in the WP article and asking whether the text provides any information about the entity''\cite{JFrank12}. Documents would be devided according to two metrics: 1) mentioning the entity or not, 2) relevance level to the entity:
\begin{itemize}
\item \textbf{Mention} 
\begin{itemize}
\item \textbf{Mention:} Document explicitly mentions target entity, such as full name, partial name, nickname, pseudonym, title, stage name.
\item \textbf{Zero-mention:} Document does not directly mention target. Could still be relevant, e.g. metonymic references like ``this administration'' -- \textgreater ``Obama''. See also synecdoche. A document could also be relevant to target entity through relation to entities mentioned in document -- apply this test question: can I learn something from this document about target entity using whatever other information I have about entity?
\end{itemize}
\item \textbf{Relevance}
\begin{itemize}
\item \textbf{Garbage:} not relevant, e.g. spam.
\item \textbf{Neutral:} Not relevant, i.e. no info could be deduced about entity, e.g., entity name used in product name, or only pertains to community of target such that no information could be learned about entity, although you can see how an automatic algorithm might have thought it was relevant.
\item \textbf{Relevant:} Relates indirectly, e.g., tangential with substantive implications, or topics or events of likely
impact on entity.
\item \textbf{Central:} Relates directly to target such that you would cite it in the WP article for this entity, e.g. entity is a
central figure in topics/events.



\end{itemize}
\end{itemize}

The details of the metric for SSF will favor systems that most closely match the changes in the ground truth time line of slot values. This is done by searching for other documents that mentioned an entity and exactly matched the slot fill strings selected by the assessors.


\begin{table}[b]
\caption{Ontology of Slot Name Categories }
\centering
\label{table:slotNameOntology}

\begin{tabular}{|c|c|c|}
\hline 
\textbf{PER} & \textbf{FAC} & \textbf{ORG} \\ 
\hline 
\begin{tabular}{@{}l@{}}Affiliate \\ AssociateOf \\ Contact\_Meet\_PlaceTime \\ AwardsWon \\ 
DateOfDeath \\ 
CauseOfDeath\\
Titles\\
FounderOf\\
EmployeeOf\end{tabular}
  &
   \begin{tabular}[b]{l}Affiliate \\ Contact\_Meet\_Entity \end{tabular} 
   & 
   \begin{tabular}{@{}l@{}}Affiliate \\ TopMembers \\ FoundedBy\end{tabular} \\ 
\hline 
\end{tabular} 
\end{table}


\begin{table}[b]
\caption{Document Chunks Distribution }
\centering
\label{table:documentsDist}

\begin{tabular}{|c|l|}
\hline 
\textbf{\# of Documents} & \textbf{Document Type}\\ 
\hline 
10988 & 	arxiv (full text, abstracts in StreamItem.other\_content) \\ \hline
34887 & CLASSIFIED (spinn3r)  \\ \hline
77674 & FORUM (spinn3r)  \\ \hline
12947 & linking (reprocessed from kba-stream-corpus-2012, same stream\_id)  \\ \hline
141936 & MAINSTREAM\_NEWS (spinn3r)  \\ \hline
4137 & MEMETRACKER (spinn3r)  \\ \hline
280629 & news (reprocessed from kba-stream-corpus-2012, same stream\_id)  \\ \hline
6347 &  REVIEW (spinn3r) \\ \hline
688848 & 	 social (reprocessed from kba-stream-corpus-2012 plus extension, same stream\_id)  \\ \hline
740987 & WEBLOG (spinn3r)  \\ \hline

  
\hline 
\end{tabular} 
\end{table}


\noindent Example 1: ``Matthew DeLorenzo and Josiah Vega, both 14 years old and students 
at Elysian Charter School, were honored Friday morning by C-SPAN and received 
\$1,500 as well as an iPod Touch after winning a nationwide video contest.''

target\_id:  http://en.wikipedia.org/wiki/Elysian\_Charter\_School

Affiliate:  ``Matthew DeLorenzo''
Affiliate:  ``Josiah Vega''

NOT an affiliate:  ``C-SPAN''
NOT an affiliate:  ``iPod Touch''

\noindent Example 2: ``Veteran songwriters and performers Ben Mason, Jeff Severson and 
Jeff Smith will perform on Saturday, April 14 at 7:30 pm at Creative Cauldron 
at ArtSpace, 410 S. Maple Avenue.''

target\_id: http://en.wikipedia.org/wiki/Jeff\_Severson

Affiliate: ``Ben Mason''
Affiliate: ``Jeff Severson''
Affiliate: ``Jeff Smith''

NOT an Affiliate: ``Creative Caldron''
NOT an Affiliate: ``Art Space''

\noindent Example 3:  ``Lt. Gov. Drew Wrigley and Robert Wefald, a retired North Dakota 
district judge and former state attorney general, unveiled the crest Friday 
during a ceremony at the North Dakota Capitol.''

target\_id: http://en.wikipedia.org/wiki/Hjemkomst\_Center

Contact\_Meet\_PlaceTime: ``Friday during a ceremony at the North Dakota Capitol''


 

%\ceg{How will each submission be evaluated?}

% Motivation


% KBA Task


% Evaluation Criteria


% Quick Discussion of our approach

